{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c62633-9941-4571-8a41-2c14a2780c8d",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "The Perceptron class in scikit-learn is a linear classification algorithm that is built on top of the Stochastic Gradient Descent (SGD) approach. It's primarily used for binary and multi-class classification tasks and implements a variant of the Perceptron algorithm, which is an early form of a neural network. Here's a breakdown of its functionality and usage:\n",
    "\n",
    "### Key Concepts:\n",
    "- Classification Algorithm: The Perceptron is a linear classifier, meaning it tries to find a hyperplane that separates the data into different classes.\n",
    "- SGD-Based Implementation: It's essentially a simplified version of SGDClassifier, where specific loss and learning rate settings make it equivalent to the Perceptron algorithm.\n",
    "\n",
    "class sklearn.linear_model.Perceptron(*, penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9efee1-1b5a-4084-bf7d-7ad0d01b9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e42101a-06ab-4eab-8c09-ebbada25c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_step_function(x):\n",
    "    return np.where(x>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9a07b4-9193-4fff-9cad-e90f2616afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self,learning_rate=0.01,n_iters=1000):\n",
    "        self.lr=learning_rate\n",
    "        self.n_iters=n_iters\n",
    "        self.activation_func=unit_step_function\n",
    "        self.bias=None\n",
    "        self.weights=None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        n_samples,n_features=X.shape\n",
    "        self.weights=np.zeros(n_features)\n",
    "        self.bias=0\n",
    "        y=np.where(y>0,1,0)\n",
    "        for i in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(X):\n",
    "                z=np.dot(x_i,self.weights)+self.bias\n",
    "                y_pred=self.activation_func(z)\n",
    "                self.weights+=self.lr*(y[idx]-y_pred)*x_i\n",
    "                self.bias+=self.lr*(y[idx]-y_pred)\n",
    "                \n",
    "    def predict(self,X):\n",
    "        z=np.dot(X,self.weights)+self.bias\n",
    "        return self.activation_func(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8290499-92bd-47db-8ab4-bcdf7f3b81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X,y=datasets.make_blobs(n_samples=1000,n_features=2,centers=2,cluster_std=1.05,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee44c6f-4894-40e1-8b8f-c128457b899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26d662a-7706-4340-9dab-623a69044439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=Perceptron()\n",
    "clf.fit(X_train,y_train)\n",
    "predictions=clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b962126a-8db5-4761-960c-5c98b01e63b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1282f0f3-f3d1-45ca-9ac8-af1258651d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    c0,c1,acc0,acc1=0,0,0,0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]==0:\n",
    "            c0+=1\n",
    "            if y_true[i]==y_pred[i]:\n",
    "                acc0+=1\n",
    "        else:\n",
    "            c1+=1\n",
    "            if y_true[i]==y_pred[i]:\n",
    "                acc1+=1\n",
    "                \n",
    "    return [acc0/c0 , acc1/c1]\n",
    "accuracy(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a78b49-63d6-451c-b1ea-91f23c985371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "634ef97f-01ba-44a1-898f-f7214ee55fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"diabetes.csv\")\n",
    "X=df.drop(columns=[\"Outcome\"])\n",
    "y=df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faaa9be9-6ee9-4b04-a186-b2d36299c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1234)\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "x_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f4e1d1-43ef-4c9e-98b1-b582bca3e790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=Perceptron()\n",
    "clf.fit(X_train,y_train)\n",
    "predictions=clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ee41f9-c562-4db7-8ebf-93ce8dfbcdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=np.where(y_test<=0,0,1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78a0c4a9-ba20-43f4-9e55-244a1c68759d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9797979797979798, 0.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba8682-94c1-424e-8ff0-5b4bdb116b13",
   "metadata": {},
   "source": [
    "### Parameters:\n",
    "- penalty: Regularization term to prevent overfitting. Options include:\n",
    "<b>'l2'</b> for Ridge regression.\n",
    "<b>'l1'</b> for Lasso regression.\n",
    "<b>'elasticnet'</b> for a combination of both.\n",
    "- alpha: Regularization strength multiplier for the penalty term (default 0.0001).\n",
    "- fit_intercept: Whether to calculate the intercept for the model. If False, data should be centered.\n",
    "- max_iter: Maximum number of epochs, i.e., how many times the algorithm will pass through the training data.\n",
    "- tol: The stopping criterion for the optimization.\n",
    "- shuffle: Whether to shuffle the training data after each epoch.\n",
    "- random_state: Controls the shuffling and other random number generation processes for reproducibility.\n",
    "- early_stopping: Stops training early if the validation score does not improve.\n",
    "- warm_start: Reuses the solution of the previous fit to continue training from where it left off.\n",
    "- class_weight: Balances classes by assigning higher weights to minority classes.\n",
    "- n_jobs: Number of CPU cores to use for computation (in multi-class classification problems)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "120666b0-d699-49f5-8d68-f5060e2ae840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyanb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Perceptron was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Initialize the Perceptron model\n",
    "clf = Perceptron()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "predictions=clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "020e3120-8e42-4937-8989-7ee982943d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea3ded04-1189-4f7a-b62a-9f999c48e8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9292929292929293, 0.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8330fb-4fc6-441a-9fb0-a68fd54e0bd4",
   "metadata": {},
   "source": [
    "### Methods:\n",
    "- fit(X, y): Trains the perceptron model on the dataset X and the corresponding labels y.\n",
    "- predict(X): Predicts the class labels for the data X.\n",
    "- partial_fit(X, y): Performs one epoch of SGD on the provided data. Useful when handling large datasets.\n",
    "- score(X, y): Returns the mean accuracy of the predictions on a test dataset.\n",
    "- decision_function(X): Provides confidence scores for the predictions.\n",
    "\n",
    "### Attributes:\n",
    "- coef_: The weight coefficients for the features.\n",
    "- intercept_: The bias term (intercept).\n",
    "- n_iter_: The number of iterations the model has run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350e5a2-5632-4d94-81b6-4bd95240d5b5",
   "metadata": {},
   "source": [
    "### Practical Example:\n",
    "- from sklearn.datasets import load_digits<br>\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "- Load digits dataset<br>\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "- Initialize the Perceptron model<br>\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "\n",
    "- Train the model<br>\n",
    "clf.fit(X, y)\n",
    "\n",
    "- Evaluate the accuracy<br>\n",
    "score = clf.score(X, y)<br>\n",
    "print(f\"Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed8a2c-cd58-42c8-80f7-109569a2ab8f",
   "metadata": {},
   "source": [
    "- The Perceptron algorithm is sensitive to feature scaling. You may want to standardize your dataset before using it.\n",
    "- In practice, more sophisticated algorithms such as Support Vector Machines (SVMs) or Logistic Regression often perform better for linear classification tasks due to additional hyperparameter tuning and optimization options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c3a2b-badf-4f47-89c5-12e658391f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
